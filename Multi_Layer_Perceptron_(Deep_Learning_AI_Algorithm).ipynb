{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sisco1113/multi-layer-perceptron-deep-learning-AI-algorithm-/blob/main/Multi_Layer_Perceptron_(Deep_Learning_AI_Algorithm).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j-pb0cO4InzF"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#\n",
        "#    1. Number of times pregnant\n",
        "#    2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test #    3. Diastolic blood pressure (mm Hg)\n",
        "#    4. Triceps skin fold thickness (mm) #    5. 2-Hour serum insulin (mu U/ml)\n",
        "#    6. Body mass index (weight in kg/(height in m)^2)\n",
        "#    7. Diabetes pedigree function\n",
        "#    8. Age (years)\n",
        "#    9. Class variable (0 or 1)\n",
        "#\n",
        "# complete columns array\n",
        "columns=[\"Number of times pregnant\",\n",
        "           \"Plasma glucose concentration a 2 hours\",\n",
        "           \"Diastolic blood pressure\",\n",
        "           \"Triceps skin fold thickness\",\n",
        "           \"2-Hour serum insulin\",\n",
        "           \"Body mass index\",\n",
        "           \"Diabetes pedigree function\",\n",
        "           \"Age\",\n",
        "           \"Class\"]\n",
        "\n",
        "pima_data = pd.read_csv(\"pima-diabetes.csv\", names=columns)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HWwfY5RKInzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e70dfeae-04ed-47e5-c759-650c9ab32f51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension: \n",
            " (768, 9)\n",
            "Datatype: \n",
            " Number of times pregnant                    int64\n",
            "Plasma glucose concentration a 2 hours      int64\n",
            "Diastolic blood pressure                    int64\n",
            "Triceps skin fold thickness                 int64\n",
            "2-Hour serum insulin                        int64\n",
            "Body mass index                           float64\n",
            "Diabetes pedigree function                float64\n",
            "Age                                         int64\n",
            "Class                                       int64\n",
            "dtype: object\n",
            "First 5 rows: \n",
            "    Number of times pregnant  Plasma glucose concentration a 2 hours  \\\n",
            "0                         6                                     148   \n",
            "1                         1                                      85   \n",
            "2                         8                                     183   \n",
            "3                         1                                      89   \n",
            "4                         0                                     137   \n",
            "\n",
            "   Diastolic blood pressure  Triceps skin fold thickness  \\\n",
            "0                        72                           35   \n",
            "1                        66                           29   \n",
            "2                        64                            0   \n",
            "3                        66                           23   \n",
            "4                        40                           35   \n",
            "\n",
            "   2-Hour serum insulin  Body mass index  Diabetes pedigree function  Age  \\\n",
            "0                     0             33.6                       0.627   50   \n",
            "1                     0             26.6                       0.351   31   \n",
            "2                     0             23.3                       0.672   32   \n",
            "3                    94             28.1                       0.167   21   \n",
            "4                   168             43.1                       2.288   33   \n",
            "\n",
            "   Class  \n",
            "0      1  \n",
            "1      0  \n",
            "2      1  \n",
            "3      0  \n",
            "4      1  \n",
            "Mean, count, std, min, max, etc. for each attribute: \n",
            "        Number of times pregnant  Plasma glucose concentration a 2 hours  \\\n",
            "count                768.000000                              768.000000   \n",
            "mean                   3.845052                              120.894531   \n",
            "std                    3.369578                               31.972618   \n",
            "min                    0.000000                                0.000000   \n",
            "25%                    1.000000                               99.000000   \n",
            "50%                    3.000000                              117.000000   \n",
            "75%                    6.000000                              140.250000   \n",
            "max                   17.000000                              199.000000   \n",
            "\n",
            "       Diastolic blood pressure  Triceps skin fold thickness  \\\n",
            "count                768.000000                   768.000000   \n",
            "mean                  69.105469                    20.536458   \n",
            "std                   19.355807                    15.952218   \n",
            "min                    0.000000                     0.000000   \n",
            "25%                   62.000000                     0.000000   \n",
            "50%                   72.000000                    23.000000   \n",
            "75%                   80.000000                    32.000000   \n",
            "max                  122.000000                    99.000000   \n",
            "\n",
            "       2-Hour serum insulin  Body mass index  Diabetes pedigree function  \\\n",
            "count            768.000000       768.000000                  768.000000   \n",
            "mean              79.799479        31.992578                    0.471876   \n",
            "std              115.244002         7.884160                    0.331329   \n",
            "min                0.000000         0.000000                    0.078000   \n",
            "25%                0.000000        27.300000                    0.243750   \n",
            "50%               30.500000        32.000000                    0.372500   \n",
            "75%              127.250000        36.600000                    0.626250   \n",
            "max              846.000000        67.100000                    2.420000   \n",
            "\n",
            "              Age       Class  \n",
            "count  768.000000  768.000000  \n",
            "mean    33.240885    0.348958  \n",
            "std     11.760232    0.476951  \n",
            "min     21.000000    0.000000  \n",
            "25%     24.000000    0.000000  \n",
            "50%     29.000000    0.000000  \n",
            "75%     41.000000    1.000000  \n",
            "max     81.000000    1.000000  \n"
          ]
        }
      ],
      "source": [
        "# show dimension, datatype, and first 5 rows of pima_data.\n",
        "# use shape, dtypes, describe\n",
        "# for each attribute, show mean, count, std, min, max, etc\n",
        "# use describe\n",
        "print(\"Dimension: \\n\", pima_data.shape)\n",
        "print(\"Datatype: \\n\", pima_data.dtypes)\n",
        "print(\"First 5 rows: \\n\", pima_data.head())\n",
        "print(\"Mean, count, std, min, max, etc. for each attribute: \\n\", pima_data.describe())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1nbn4BtBInzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39b124e0-b344-4943-fdbb-ed841e5cb131"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized attributes: \n",
            "        Number of times pregnant  Plasma glucose concentration a 2 hours  \\\n",
            "count                768.000000                              768.000000   \n",
            "mean                   0.226180                                0.607510   \n",
            "std                    0.198210                                0.160666   \n",
            "min                    0.000000                                0.000000   \n",
            "25%                    0.058824                                0.497487   \n",
            "50%                    0.176471                                0.587940   \n",
            "75%                    0.352941                                0.704774   \n",
            "max                    1.000000                                1.000000   \n",
            "\n",
            "       Diastolic blood pressure  Triceps skin fold thickness  \\\n",
            "count                768.000000                   768.000000   \n",
            "mean                   0.566438                     0.207439   \n",
            "std                    0.158654                     0.161134   \n",
            "min                    0.000000                     0.000000   \n",
            "25%                    0.508197                     0.000000   \n",
            "50%                    0.590164                     0.232323   \n",
            "75%                    0.655738                     0.323232   \n",
            "max                    1.000000                     1.000000   \n",
            "\n",
            "       2-Hour serum insulin  Body mass index  Diabetes pedigree function  \\\n",
            "count            768.000000       768.000000                  768.000000   \n",
            "mean               0.094326         0.476790                    0.168179   \n",
            "std                0.136222         0.117499                    0.141473   \n",
            "min                0.000000         0.000000                    0.000000   \n",
            "25%                0.000000         0.406855                    0.070773   \n",
            "50%                0.036052         0.476900                    0.125747   \n",
            "75%                0.150414         0.545455                    0.234095   \n",
            "max                1.000000         1.000000                    1.000000   \n",
            "\n",
            "              Age  \n",
            "count  768.000000  \n",
            "mean     0.204015  \n",
            "std      0.196004  \n",
            "min      0.000000  \n",
            "25%      0.050000  \n",
            "50%      0.133333  \n",
            "75%      0.333333  \n",
            "max      1.000000  \n"
          ]
        }
      ],
      "source": [
        "#\n",
        "#We are going to normalize(scale) the values of each attributes.\n",
        "#\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# Choose one of these\n",
        "# normalize every attribute (except target attribute) using MinMaxScaler\n",
        "#scaler = MinMaxScaler()\n",
        "# Instead of ‘MinMaxScaler’, you can also use ‘StandardScaler’\n",
        "#scaler = StandardScaler()\n",
        "\n",
        "#\n",
        "#*** DON’T normalize target(class) attribute\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "in_columns=columns[:-1]\n",
        "\n",
        "\n",
        "df_scaled = scaler.fit_transform(pima_data[in_columns].values)\n",
        "pima_data_norm= pd.DataFrame(df_scaled, columns=in_columns)\n",
        "print(\"Normalized attributes: \\n\", pima_data_norm.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VwxAv9ydInzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "143ad05a-563c-46c8-9937-1604a0543a16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: \n",
            " (537, 8)\n",
            "X_test: \n",
            " (231, 8)\n",
            "Y_train: \n",
            " (537,)\n",
            "Y_test: \n",
            " (231,)\n",
            "First 5 rows of X_train:\n",
            "      Number of times pregnant  Plasma glucose concentration a 2 hours  \\\n",
            "334                         1                                      95   \n",
            "139                         5                                     105   \n",
            "485                         0                                     135   \n",
            "547                         4                                     131   \n",
            "18                          1                                     103   \n",
            "\n",
            "     Diastolic blood pressure  Triceps skin fold thickness  \\\n",
            "334                        60                           18   \n",
            "139                        72                           29   \n",
            "485                        68                           42   \n",
            "547                        68                           21   \n",
            "18                         30                           38   \n",
            "\n",
            "     2-Hour serum insulin  Body mass index  Diabetes pedigree function  Age  \n",
            "334                    58             23.9                       0.260   22  \n",
            "139                   325             36.9                       0.159   28  \n",
            "485                   250             42.3                       0.365   24  \n",
            "547                   166             33.1                       0.160   28  \n",
            "18                     83             43.3                       0.183   33  \n",
            "First 5 rows of X_test:\n",
            "      Number of times pregnant  Plasma glucose concentration a 2 hours  \\\n",
            "668                         6                                      98   \n",
            "324                         2                                     112   \n",
            "624                         2                                     108   \n",
            "690                         8                                     107   \n",
            "473                         7                                     136   \n",
            "\n",
            "     Diastolic blood pressure  Triceps skin fold thickness  \\\n",
            "668                        58                           33   \n",
            "324                        75                           32   \n",
            "624                        64                            0   \n",
            "690                        80                            0   \n",
            "473                        90                            0   \n",
            "\n",
            "     2-Hour serum insulin  Body mass index  Diabetes pedigree function  Age  \n",
            "668                   190             34.0                       0.430   43  \n",
            "324                     0             35.7                       0.148   21  \n",
            "624                     0             30.8                       0.158   21  \n",
            "690                     0             24.6                       0.856   34  \n",
            "473                     0             29.9                       0.210   50  \n",
            "First 5 rows of Y_train:\n",
            " 334    0\n",
            "139    0\n",
            "485    1\n",
            "547    0\n",
            "18     0\n",
            "Name: Class, dtype: int64\n",
            "First 5 rows of Y_test:\n",
            " 668    0\n",
            "324    0\n",
            "624    0\n",
            "690    0\n",
            "473    0\n",
            "Name: Class, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# With .pop() command, ‘class’ target attribute is extracted.\n",
        "# select input attributes without target attributes\n",
        "# refer to HW 1 and create Y & X in HW 1\n",
        "target_attribute = pima_data.pop('Class')\n",
        "input_attributes = pima_data\n",
        "\n",
        "Y = target_attribute\n",
        "X = input_attributes\n",
        "\n",
        "# split X, Y into X_train, X_test, Y_train, Y_test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "#  Show that split is correctly done\n",
        "# you can show the shape of each data & first 5 rows of each data\n",
        "print(\"X_train: \\n\", X_train.shape)\n",
        "print(\"X_test: \\n\", X_test.shape)\n",
        "print(\"Y_train: \\n\", Y_train.shape)\n",
        "print(\"Y_test: \\n\", Y_test.shape)\n",
        "\n",
        "print(\"First 5 rows of X_train:\\n\", X_train.head())\n",
        "print(\"First 5 rows of X_test:\\n\", X_test.head())\n",
        "print(\"First 5 rows of Y_train:\\n\", Y_train.head())\n",
        "print(\"First 5 rows of Y_test:\\n\", Y_test.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2EeX400wInzM"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(12, input_dim=8, activation = 'relu'))\n",
        "model.add(Dense(8, activation = 'relu'))\n",
        "model.add(Dense(8, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7cBIKer0InzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "468f3d03-c7de-44c1-92de-8e7a5d3aa9ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 1.5097 - accuracy: 0.5573\n",
            "Epoch 2/50\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.7016 - accuracy: 0.6458\n",
            "Epoch 3/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6733 - accuracy: 0.6445\n",
            "Epoch 4/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6633 - accuracy: 0.6432\n",
            "Epoch 5/50\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.6484\n",
            "Epoch 6/50\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6538 - accuracy: 0.6562\n",
            "Epoch 7/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6567 - accuracy: 0.6497\n",
            "Epoch 8/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6657 - accuracy: 0.6497\n",
            "Epoch 9/50\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6482 - accuracy: 0.6497\n",
            "Epoch 10/50\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6527 - accuracy: 0.6523\n",
            "Epoch 11/50\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6467 - accuracy: 0.6523\n",
            "Epoch 12/50\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6462 - accuracy: 0.6510\n",
            "Epoch 13/50\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6429 - accuracy: 0.6510\n",
            "Epoch 14/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.6510\n",
            "Epoch 15/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.6510\n",
            "Epoch 16/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6497\n",
            "Epoch 17/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6388 - accuracy: 0.6497\n",
            "Epoch 18/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6305 - accuracy: 0.6510\n",
            "Epoch 19/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.6523\n",
            "Epoch 20/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.6510\n",
            "Epoch 21/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.6510\n",
            "Epoch 22/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.6497\n",
            "Epoch 23/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.6510\n",
            "Epoch 24/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6497\n",
            "Epoch 25/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6186 - accuracy: 0.6510\n",
            "Epoch 26/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6510\n",
            "Epoch 27/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6310 - accuracy: 0.6510\n",
            "Epoch 28/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.6497\n",
            "Epoch 29/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6156 - accuracy: 0.6510\n",
            "Epoch 30/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.6510\n",
            "Epoch 31/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6139 - accuracy: 0.6497\n",
            "Epoch 32/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6145 - accuracy: 0.6510\n",
            "Epoch 33/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6186 - accuracy: 0.6510\n",
            "Epoch 34/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6146 - accuracy: 0.6497\n",
            "Epoch 35/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.6523\n",
            "Epoch 36/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6114 - accuracy: 0.6510\n",
            "Epoch 37/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.6510\n",
            "Epoch 38/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.6510\n",
            "Epoch 39/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.6510\n",
            "Epoch 40/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6121 - accuracy: 0.6523\n",
            "Epoch 41/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6089 - accuracy: 0.6510\n",
            "Epoch 42/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6085 - accuracy: 0.6523\n",
            "Epoch 43/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6114 - accuracy: 0.6510\n",
            "Epoch 44/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6066 - accuracy: 0.6510\n",
            "Epoch 45/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.6484\n",
            "Epoch 46/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6128 - accuracy: 0.6523\n",
            "Epoch 47/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.6497\n",
            "Epoch 48/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6095 - accuracy: 0.6510\n",
            "Epoch 49/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6031 - accuracy: 0.6510\n",
            "Epoch 50/50\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.6523\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6061 - accuracy: 0.6537\n",
            "Loss:  0.6061399579048157\n",
            "Accuracy:  0.6536796689033508\n",
            "8/8 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# 1) use ‘adam’ optimizer, 2) loss function is binary_crossentropy\n",
        "# 3) metrics = accuracy\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# change epoch values\n",
        "model.fit(X, Y, epochs=50, batch_size=10)\n",
        "\n",
        "# check the performance of the model\n",
        "# use evaluate, predict, etc\n",
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "predictions = model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, batch_size=30, epochs=60, validation_data=(X_test, Y_test))\n",
        "\n",
        "# check the performance of the model\n",
        "# use evaluate, predict, etc\n",
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "id": "apQKdT-hqsCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2697f703-4216-42d0-fc62-8854cce30c30"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5950 - accuracy: 0.6518 - val_loss: 0.6113 - val_accuracy: 0.6537\n",
            "Epoch 2/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5963 - accuracy: 0.6518 - val_loss: 0.6083 - val_accuracy: 0.6537\n",
            "Epoch 3/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5982 - accuracy: 0.6518 - val_loss: 0.6058 - val_accuracy: 0.6537\n",
            "Epoch 4/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5994 - accuracy: 0.6518 - val_loss: 0.6097 - val_accuracy: 0.6537\n",
            "Epoch 5/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5941 - accuracy: 0.6518 - val_loss: 0.6084 - val_accuracy: 0.6537\n",
            "Epoch 6/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.6518 - val_loss: 0.6220 - val_accuracy: 0.6537\n",
            "Epoch 7/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6000 - accuracy: 0.6536 - val_loss: 0.6060 - val_accuracy: 0.6537\n",
            "Epoch 8/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.6499 - val_loss: 0.6155 - val_accuracy: 0.6537\n",
            "Epoch 9/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5988 - accuracy: 0.6518 - val_loss: 0.6041 - val_accuracy: 0.6537\n",
            "Epoch 10/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5975 - accuracy: 0.6536 - val_loss: 0.6141 - val_accuracy: 0.6537\n",
            "Epoch 11/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.6518 - val_loss: 0.6073 - val_accuracy: 0.6537\n",
            "Epoch 12/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5970 - accuracy: 0.6518 - val_loss: 0.6130 - val_accuracy: 0.6537\n",
            "Epoch 13/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6029 - accuracy: 0.6536 - val_loss: 0.6053 - val_accuracy: 0.6537\n",
            "Epoch 14/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.6536 - val_loss: 0.6043 - val_accuracy: 0.6537\n",
            "Epoch 15/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5930 - accuracy: 0.6518 - val_loss: 0.6051 - val_accuracy: 0.6537\n",
            "Epoch 16/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5985 - accuracy: 0.6536 - val_loss: 0.6076 - val_accuracy: 0.6537\n",
            "Epoch 17/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5939 - accuracy: 0.6499 - val_loss: 0.6067 - val_accuracy: 0.6537\n",
            "Epoch 18/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5924 - accuracy: 0.6518 - val_loss: 0.6086 - val_accuracy: 0.6537\n",
            "Epoch 19/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.6536 - val_loss: 0.6131 - val_accuracy: 0.6537\n",
            "Epoch 20/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5932 - accuracy: 0.6518 - val_loss: 0.6060 - val_accuracy: 0.6537\n",
            "Epoch 21/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5920 - accuracy: 0.6536 - val_loss: 0.6058 - val_accuracy: 0.6537\n",
            "Epoch 22/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5911 - accuracy: 0.6555 - val_loss: 0.6115 - val_accuracy: 0.6537\n",
            "Epoch 23/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5926 - accuracy: 0.6518 - val_loss: 0.6053 - val_accuracy: 0.6537\n",
            "Epoch 24/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5940 - accuracy: 0.6536 - val_loss: 0.6076 - val_accuracy: 0.6537\n",
            "Epoch 25/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5978 - accuracy: 0.6536 - val_loss: 0.6085 - val_accuracy: 0.6537\n",
            "Epoch 26/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5886 - accuracy: 0.6555 - val_loss: 0.6066 - val_accuracy: 0.6537\n",
            "Epoch 27/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5949 - accuracy: 0.6518 - val_loss: 0.6060 - val_accuracy: 0.6537\n",
            "Epoch 28/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5931 - accuracy: 0.6499 - val_loss: 0.6056 - val_accuracy: 0.6537\n",
            "Epoch 29/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5944 - accuracy: 0.6518 - val_loss: 0.6063 - val_accuracy: 0.6537\n",
            "Epoch 30/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5948 - accuracy: 0.6555 - val_loss: 0.6055 - val_accuracy: 0.6537\n",
            "Epoch 31/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5917 - accuracy: 0.6555 - val_loss: 0.6087 - val_accuracy: 0.6537\n",
            "Epoch 32/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.6518 - val_loss: 0.6161 - val_accuracy: 0.6537\n",
            "Epoch 33/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5919 - accuracy: 0.6536 - val_loss: 0.6378 - val_accuracy: 0.6537\n",
            "Epoch 34/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.6518 - val_loss: 0.6123 - val_accuracy: 0.6537\n",
            "Epoch 35/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5916 - accuracy: 0.6518 - val_loss: 0.6111 - val_accuracy: 0.6537\n",
            "Epoch 36/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5929 - accuracy: 0.6555 - val_loss: 0.6139 - val_accuracy: 0.6364\n",
            "Epoch 37/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5895 - accuracy: 0.6592 - val_loss: 0.6093 - val_accuracy: 0.6537\n",
            "Epoch 38/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5959 - accuracy: 0.6536 - val_loss: 0.6123 - val_accuracy: 0.6494\n",
            "Epoch 39/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5918 - accuracy: 0.6574 - val_loss: 0.6099 - val_accuracy: 0.6450\n",
            "Epoch 40/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5952 - accuracy: 0.6629 - val_loss: 0.6124 - val_accuracy: 0.6450\n",
            "Epoch 41/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5866 - accuracy: 0.6518 - val_loss: 0.6090 - val_accuracy: 0.6667\n",
            "Epoch 42/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5872 - accuracy: 0.6574 - val_loss: 0.6153 - val_accuracy: 0.6450\n",
            "Epoch 43/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5846 - accuracy: 0.6611 - val_loss: 0.6150 - val_accuracy: 0.6494\n",
            "Epoch 44/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.6667 - val_loss: 0.6349 - val_accuracy: 0.6580\n",
            "Epoch 45/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5895 - accuracy: 0.6667 - val_loss: 0.6132 - val_accuracy: 0.6494\n",
            "Epoch 46/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5866 - accuracy: 0.6536 - val_loss: 0.6111 - val_accuracy: 0.6537\n",
            "Epoch 47/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6032 - accuracy: 0.6611 - val_loss: 0.6161 - val_accuracy: 0.6494\n",
            "Epoch 48/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5794 - accuracy: 0.6667 - val_loss: 0.6236 - val_accuracy: 0.6580\n",
            "Epoch 49/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5836 - accuracy: 0.6667 - val_loss: 0.6205 - val_accuracy: 0.6623\n",
            "Epoch 50/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6007 - accuracy: 0.6685 - val_loss: 0.6201 - val_accuracy: 0.6623\n",
            "Epoch 51/60\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5794 - accuracy: 0.6611 - val_loss: 0.6139 - val_accuracy: 0.6580\n",
            "Epoch 52/60\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5780 - accuracy: 0.6723 - val_loss: 0.6133 - val_accuracy: 0.6667\n",
            "Epoch 53/60\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5806 - accuracy: 0.6667 - val_loss: 0.6160 - val_accuracy: 0.6580\n",
            "Epoch 54/60\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5795 - accuracy: 0.6704 - val_loss: 0.6273 - val_accuracy: 0.6623\n",
            "Epoch 55/60\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5809 - accuracy: 0.6574 - val_loss: 0.6115 - val_accuracy: 0.6494\n",
            "Epoch 56/60\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5800 - accuracy: 0.6685 - val_loss: 0.6116 - val_accuracy: 0.6623\n",
            "Epoch 57/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5816 - accuracy: 0.6723 - val_loss: 0.6093 - val_accuracy: 0.6667\n",
            "Epoch 58/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5823 - accuracy: 0.6648 - val_loss: 0.6169 - val_accuracy: 0.6667\n",
            "Epoch 59/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5775 - accuracy: 0.6667 - val_loss: 0.6158 - val_accuracy: 0.6667\n",
            "Epoch 60/60\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5827 - accuracy: 0.6741 - val_loss: 0.6079 - val_accuracy: 0.6580\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.6580\n",
            "Loss:  0.6078685522079468\n",
            "Accuracy:  0.6580086350440979\n",
            "8/8 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, batch_size=25, epochs=55, validation_data=(X_test, Y_test))\n",
        "\n",
        "# check the performance of the model\n",
        "# use evaluate, predict, etc\n",
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "id": "2JzPIuVgqyA9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45b8c259-5c15-4984-8927-3984e813939f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/55\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.5745 - accuracy: 0.6611 - val_loss: 0.6281 - val_accuracy: 0.6580\n",
            "Epoch 2/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5908 - accuracy: 0.6667 - val_loss: 0.6153 - val_accuracy: 0.6623\n",
            "Epoch 3/55\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.5957 - accuracy: 0.6704 - val_loss: 0.6115 - val_accuracy: 0.6710\n",
            "Epoch 4/55\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5794 - accuracy: 0.6778 - val_loss: 0.6212 - val_accuracy: 0.6926\n",
            "Epoch 5/55\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.5790 - accuracy: 0.6648 - val_loss: 0.6108 - val_accuracy: 0.6623\n",
            "Epoch 6/55\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.5789 - accuracy: 0.6555 - val_loss: 0.6119 - val_accuracy: 0.6667\n",
            "Epoch 7/55\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5744 - accuracy: 0.6592 - val_loss: 0.6522 - val_accuracy: 0.6667\n",
            "Epoch 8/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5912 - accuracy: 0.6648 - val_loss: 0.6144 - val_accuracy: 0.6710\n",
            "Epoch 9/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5771 - accuracy: 0.6536 - val_loss: 0.6068 - val_accuracy: 0.6580\n",
            "Epoch 10/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5805 - accuracy: 0.6667 - val_loss: 0.6173 - val_accuracy: 0.6753\n",
            "Epoch 11/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5854 - accuracy: 0.6592 - val_loss: 0.6101 - val_accuracy: 0.6753\n",
            "Epoch 12/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5719 - accuracy: 0.6723 - val_loss: 0.6166 - val_accuracy: 0.6580\n",
            "Epoch 13/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5767 - accuracy: 0.6574 - val_loss: 0.6149 - val_accuracy: 0.6753\n",
            "Epoch 14/55\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5735 - accuracy: 0.6704 - val_loss: 0.5996 - val_accuracy: 0.6883\n",
            "Epoch 15/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5827 - accuracy: 0.6611 - val_loss: 0.6053 - val_accuracy: 0.6667\n",
            "Epoch 16/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5760 - accuracy: 0.6629 - val_loss: 0.6077 - val_accuracy: 0.6797\n",
            "Epoch 17/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5804 - accuracy: 0.6555 - val_loss: 0.6133 - val_accuracy: 0.6710\n",
            "Epoch 18/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5885 - accuracy: 0.6611 - val_loss: 0.6132 - val_accuracy: 0.6710\n",
            "Epoch 19/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5734 - accuracy: 0.6760 - val_loss: 0.6593 - val_accuracy: 0.6537\n",
            "Epoch 20/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5825 - accuracy: 0.6592 - val_loss: 0.6091 - val_accuracy: 0.6710\n",
            "Epoch 21/55\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5757 - accuracy: 0.6741 - val_loss: 0.6079 - val_accuracy: 0.6797\n",
            "Epoch 22/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.6648 - val_loss: 0.6182 - val_accuracy: 0.6580\n",
            "Epoch 23/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5775 - accuracy: 0.6667 - val_loss: 0.6135 - val_accuracy: 0.6753\n",
            "Epoch 24/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5760 - accuracy: 0.6704 - val_loss: 0.6093 - val_accuracy: 0.6753\n",
            "Epoch 25/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.6778 - val_loss: 0.6362 - val_accuracy: 0.6797\n",
            "Epoch 26/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5752 - accuracy: 0.6723 - val_loss: 0.6120 - val_accuracy: 0.6797\n",
            "Epoch 27/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5680 - accuracy: 0.6629 - val_loss: 0.6054 - val_accuracy: 0.6710\n",
            "Epoch 28/55\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5714 - accuracy: 0.6685 - val_loss: 0.6162 - val_accuracy: 0.6710\n",
            "Epoch 29/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5710 - accuracy: 0.6741 - val_loss: 0.6159 - val_accuracy: 0.6710\n",
            "Epoch 30/55\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.6685 - val_loss: 0.6067 - val_accuracy: 0.6667\n",
            "Epoch 31/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5729 - accuracy: 0.6611 - val_loss: 0.6033 - val_accuracy: 0.6710\n",
            "Epoch 32/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5781 - accuracy: 0.6499 - val_loss: 0.6051 - val_accuracy: 0.6710\n",
            "Epoch 33/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5735 - accuracy: 0.6685 - val_loss: 0.6291 - val_accuracy: 0.6623\n",
            "Epoch 34/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5779 - accuracy: 0.6629 - val_loss: 0.6075 - val_accuracy: 0.6797\n",
            "Epoch 35/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.6723 - val_loss: 0.6228 - val_accuracy: 0.6667\n",
            "Epoch 36/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5718 - accuracy: 0.6704 - val_loss: 0.6119 - val_accuracy: 0.6623\n",
            "Epoch 37/55\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.6723 - val_loss: 0.6065 - val_accuracy: 0.6710\n",
            "Epoch 38/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5748 - accuracy: 0.6667 - val_loss: 0.6118 - val_accuracy: 0.6667\n",
            "Epoch 39/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5739 - accuracy: 0.6723 - val_loss: 0.6080 - val_accuracy: 0.6667\n",
            "Epoch 40/55\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.6555 - val_loss: 0.6127 - val_accuracy: 0.6710\n",
            "Epoch 41/55\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.6704 - val_loss: 0.6110 - val_accuracy: 0.6580\n",
            "Epoch 42/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5651 - accuracy: 0.6648 - val_loss: 0.6204 - val_accuracy: 0.6753\n",
            "Epoch 43/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5748 - accuracy: 0.6611 - val_loss: 0.6265 - val_accuracy: 0.6623\n",
            "Epoch 44/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5676 - accuracy: 0.6797 - val_loss: 0.6095 - val_accuracy: 0.6797\n",
            "Epoch 45/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.6778 - val_loss: 0.6101 - val_accuracy: 0.6710\n",
            "Epoch 46/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5711 - accuracy: 0.6760 - val_loss: 0.6214 - val_accuracy: 0.6623\n",
            "Epoch 47/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5711 - accuracy: 0.6592 - val_loss: 0.6092 - val_accuracy: 0.6667\n",
            "Epoch 48/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5730 - accuracy: 0.6723 - val_loss: 0.6071 - val_accuracy: 0.6710\n",
            "Epoch 49/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.6741 - val_loss: 0.6057 - val_accuracy: 0.6710\n",
            "Epoch 50/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5685 - accuracy: 0.6704 - val_loss: 0.6260 - val_accuracy: 0.6537\n",
            "Epoch 51/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5665 - accuracy: 0.6629 - val_loss: 0.6145 - val_accuracy: 0.6623\n",
            "Epoch 52/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5744 - accuracy: 0.6685 - val_loss: 0.6072 - val_accuracy: 0.6753\n",
            "Epoch 53/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5735 - accuracy: 0.6741 - val_loss: 0.6178 - val_accuracy: 0.6710\n",
            "Epoch 54/55\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.6723 - val_loss: 0.6074 - val_accuracy: 0.6667\n",
            "Epoch 55/55\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5709 - accuracy: 0.6574 - val_loss: 0.6061 - val_accuracy: 0.6710\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.6710\n",
            "Loss:  0.6060904860496521\n",
            "Accuracy:  0.6709956526756287\n",
            "8/8 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, batch_size=30, epochs=45, validation_data=(X_test, Y_test))\n",
        "\n",
        "# check the performance of the model\n",
        "# use evaluate, predict, etc\n",
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "id": "z2UX2vl7qx6m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4765c8b4-50bc-44c6-d094-a5344d54f99e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5666 - accuracy: 0.6685 - val_loss: 0.6077 - val_accuracy: 0.6753\n",
            "Epoch 2/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5649 - accuracy: 0.6704 - val_loss: 0.6094 - val_accuracy: 0.6710\n",
            "Epoch 3/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5681 - accuracy: 0.6574 - val_loss: 0.6224 - val_accuracy: 0.6710\n",
            "Epoch 4/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5682 - accuracy: 0.6760 - val_loss: 0.6051 - val_accuracy: 0.6753\n",
            "Epoch 5/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5663 - accuracy: 0.6704 - val_loss: 0.6075 - val_accuracy: 0.6797\n",
            "Epoch 6/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5622 - accuracy: 0.6778 - val_loss: 0.6155 - val_accuracy: 0.6840\n",
            "Epoch 7/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5696 - accuracy: 0.6704 - val_loss: 0.6084 - val_accuracy: 0.6753\n",
            "Epoch 8/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5613 - accuracy: 0.6778 - val_loss: 0.6139 - val_accuracy: 0.6710\n",
            "Epoch 9/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5628 - accuracy: 0.6797 - val_loss: 0.6074 - val_accuracy: 0.6667\n",
            "Epoch 10/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5684 - accuracy: 0.6704 - val_loss: 0.6138 - val_accuracy: 0.6710\n",
            "Epoch 11/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5647 - accuracy: 0.6778 - val_loss: 0.6278 - val_accuracy: 0.6623\n",
            "Epoch 12/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5612 - accuracy: 0.6741 - val_loss: 0.6065 - val_accuracy: 0.6753\n",
            "Epoch 13/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5706 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6580\n",
            "Epoch 14/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5670 - accuracy: 0.6704 - val_loss: 0.6057 - val_accuracy: 0.6710\n",
            "Epoch 15/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5631 - accuracy: 0.6723 - val_loss: 0.6061 - val_accuracy: 0.6623\n",
            "Epoch 16/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5711 - accuracy: 0.6797 - val_loss: 0.6149 - val_accuracy: 0.6623\n",
            "Epoch 17/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5624 - accuracy: 0.6834 - val_loss: 0.6104 - val_accuracy: 0.6623\n",
            "Epoch 18/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5661 - accuracy: 0.6723 - val_loss: 0.6067 - val_accuracy: 0.6667\n",
            "Epoch 19/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5666 - accuracy: 0.6648 - val_loss: 0.6181 - val_accuracy: 0.6623\n",
            "Epoch 20/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5696 - accuracy: 0.6685 - val_loss: 0.6322 - val_accuracy: 0.6494\n",
            "Epoch 21/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5589 - accuracy: 0.6648 - val_loss: 0.6684 - val_accuracy: 0.6623\n",
            "Epoch 22/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5686 - accuracy: 0.6816 - val_loss: 0.6183 - val_accuracy: 0.6667\n",
            "Epoch 23/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5644 - accuracy: 0.6685 - val_loss: 0.6044 - val_accuracy: 0.6710\n",
            "Epoch 24/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.6685 - val_loss: 0.6088 - val_accuracy: 0.6667\n",
            "Epoch 25/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5607 - accuracy: 0.6778 - val_loss: 0.6089 - val_accuracy: 0.6667\n",
            "Epoch 26/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5606 - accuracy: 0.6723 - val_loss: 0.6154 - val_accuracy: 0.6623\n",
            "Epoch 27/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5566 - accuracy: 0.6648 - val_loss: 0.6145 - val_accuracy: 0.6710\n",
            "Epoch 28/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5604 - accuracy: 0.6667 - val_loss: 0.6078 - val_accuracy: 0.6667\n",
            "Epoch 29/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.6685 - val_loss: 0.6046 - val_accuracy: 0.6667\n",
            "Epoch 30/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5709 - accuracy: 0.6611 - val_loss: 0.6101 - val_accuracy: 0.6710\n",
            "Epoch 31/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5574 - accuracy: 0.6741 - val_loss: 0.6104 - val_accuracy: 0.6667\n",
            "Epoch 32/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.6778 - val_loss: 0.6094 - val_accuracy: 0.6667\n",
            "Epoch 33/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5639 - accuracy: 0.6723 - val_loss: 0.6201 - val_accuracy: 0.6667\n",
            "Epoch 34/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5653 - accuracy: 0.6741 - val_loss: 0.6121 - val_accuracy: 0.6580\n",
            "Epoch 35/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5641 - accuracy: 0.6704 - val_loss: 0.6188 - val_accuracy: 0.6753\n",
            "Epoch 36/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5657 - accuracy: 0.6704 - val_loss: 0.6098 - val_accuracy: 0.6710\n",
            "Epoch 37/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5620 - accuracy: 0.6704 - val_loss: 0.6107 - val_accuracy: 0.6753\n",
            "Epoch 38/45\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5634 - accuracy: 0.6723 - val_loss: 0.6119 - val_accuracy: 0.6623\n",
            "Epoch 39/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5598 - accuracy: 0.6611 - val_loss: 0.6173 - val_accuracy: 0.6580\n",
            "Epoch 40/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5583 - accuracy: 0.6685 - val_loss: 0.6107 - val_accuracy: 0.6710\n",
            "Epoch 41/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.6611 - val_loss: 0.6071 - val_accuracy: 0.6710\n",
            "Epoch 42/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.6685 - val_loss: 0.6097 - val_accuracy: 0.6753\n",
            "Epoch 43/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5619 - accuracy: 0.6723 - val_loss: 0.6071 - val_accuracy: 0.6797\n",
            "Epoch 44/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.6778 - val_loss: 0.6085 - val_accuracy: 0.6710\n",
            "Epoch 45/45\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5649 - accuracy: 0.6704 - val_loss: 0.6108 - val_accuracy: 0.6753\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6108 - accuracy: 0.6753\n",
            "Loss:  0.6108171343803406\n",
            "Accuracy:  0.6753246784210205\n",
            "8/8 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}